<MLLD_PATTERNS>

<TOOL_ORCHESTRATION>
Coordinate multiple tools with data flow.

```mlld
var @areas = [
  {"name": "auth", "files": ["auth/*.ts"], "tests": ["test/auth/*"]},
  {"name": "api", "files": ["api/*.ts"], "tests": ["test/api/*"]}
]

exe @runQA(area) = cmd {echo "Testing @area.name" | cat}
var @results = foreach @runQA(@areas)
```
</TOOL_ORCHESTRATION>

<DATA_PIPELINES>
Chain transformations with validation.

```mlld
import { @fetchData, @validate, @transform } from @data/pipeline

var @raw = @fetchData("https://api.example.com/users")
var @valid = @validate(@raw, { schema: "user" })
var @report = @transform(@valid, { format: "report" })
show `Processed @report.count users`
```

**With built-in transforms:**

```mlld
var @data = cmd {curl -s https://api.example.com/data}
var @processed = @data | @json | @validate | @transform | @csv
output @processed to "report.csv"
```
</DATA_PIPELINES>

<CONDITIONAL_WORKFLOWS>
Route execution based on conditions.

```mlld
import { @getPR, @commentOnPR } from @company/github

var @pr = @getPR(@MLLD_PR_NUMBER)
var @status = when first [
  @pr.mergeable => "ready"
  * => "blocked"
]

when [
  @status == "ready" => @commentOnPR(@MLLD_PR_NUMBER, "Ready to merge")
  @status == "blocked" => show "Needs attention"
]
```
</CONDITIONAL_WORKFLOWS>

<GUARDED_EXECUTION>
Validate at each step before proceeding.

```mlld
var @processed = @data | @validate | @normalize | @analyze

when [
  @processed.ok => @emitReport(@processed)
  !@processed.ok => show "Validation failed"
]
```
</GUARDED_EXECUTION>

<ROUTER_PATTERN>
Score and route to different handlers.

```mlld
exe @router(message, handlers) = [
  let @scores = for @h in @handlers => {
    handler: @h.name,
    score: @h.scorer(@message)
  }
  let @best = @scores | @sortBy("score") | @first
  => when first [
    @best.score > 0.7 => @handlers[@best.handler].handle(@message)
    * => null
  ]
]
```
</ROUTER_PATTERN>

<GATE_PATTERN>
Validate or filter before proceeding.

```mlld
exe @gate(response, config) = [
  let @check = @validate(@response)
  => when first [
    !@config.required => { pass: true }
    @check.valid => { pass: true }
    * => { pass: false, reason: @check.error }
  ]
]
```
</GATE_PATTERN>

<PARALLEL_EXECUTION>
Run independent tasks concurrently.

```mlld
>> Parallel for
for parallel(3) @task in @tasks [
  let @result = @runTask(@task)
  show `Done: @task.id`
]

>> Parallel pipeline groups
var @results = || @fetchA() || @fetchB() || @fetchC()

>> With error handling
exe @runAll(tasks) = [
  let @results = for parallel @t in @tasks => @run(@t)
  => when [
    @mx.errors.length == 0 => @results
    * => @repair(@results, @mx.errors)
  ]
]
```
</PARALLEL_EXECUTION>

<LLM_INTEGRATION>
Call LLMs with structured prompts.

```mlld
import { @haiku, @sonnet } from "@lib/claude.mld"

exe @classify(text) = [
  let @prompt = `Classify this text as positive/negative/neutral: @text`
  let @response = @haiku(@prompt)
  => @response.trim().toLowerCase()
]

exe @analyze(data) = [
  let @prompt = `Analyze this data and return JSON: @data|@json`
  let @response = @sonnet(@prompt)
  => @response | @json.llm
]
```
</LLM_INTEGRATION>

<AGENT_DEFINITION>
Define agent configuration modules.

```mlld
---
id: my-agent
name: My Agent
---

var @meta = {
  id: @fm.id,
  name: @fm.name,
  workDir: "/path/to/work"
}

exe @systemPrompt(context) = template "./prompts/system.att"
exe @primaryPrompt(msg, ctx) = template "./prompts/primary.att"

var @prompts = {
  primary: @primaryPrompt
}

export { @meta, @prompts, @systemPrompt }
```
</AGENT_DEFINITION>

<PROSE_EXECUTION>
Execute LLM-interpreted DSL skills (OpenProse and custom).

The `prose {}` syntax executes LLM-interpreted DSL skills. By default it uses **OpenProse**, but any custom interpreter can be configured.

## What is Prose Execution?

Prose execution invokes skills that an LLM interprets at runtime. Unlike `run js {}` which executes deterministically, `prose {}` sends content to an LLM with specific skills enabled. This enables complex multi-agent workflows defined in a domain-specific language.

## Setup

1. Install the OpenProse plugin in Claude Code:
   ```
   /plugin marketplace add git@github.com:openprose/prose.git
   /plugin install open-prose@prose
   ```

2. Restart Claude Code and boot OpenProse:
   ```
   /prose-boot
   ```

3. Skills will prompt for approval on first use.

## Basic Usage

```mlld
import { @opus } from @mlld/prose

exe @research(topic) = prose:@opus {
  session "Research @topic"
  agent researcher { model: sonnet, skills: [web-search] }
  researcher: find current information about @topic
  output findings
}

run @research("quantum computing trends")
```

## Key Concepts

**session** - Names the workflow for context

**agent** - Defines an agent with model and skills

**loop until** - Iterates with semantic exit conditions:
```mlld
exe @refine(draft) = prose:@opus {
  session "Refine document"
  loop until **the draft meets publication standards** {
    critique @draft
    revise based on critique
  }
}
```

**parallel** - Run tasks concurrently:
```mlld
exe @gather(topics) = prose:@opus {
  session "Research multiple topics"
  parallel for each topic in @topics {
    research topic
  }
  combine results
}
```

## Template Files

For complex workflows, use external files:

```mlld
exe @workflow(ctx) = prose:@opus "./workflow.prose"
exe @workflow(ctx) = prose:@opus "./workflow.prose.att"  >> ATT interpolation
```

## Custom Interpreters

Use any LLM-interpreted DSL by configuring different skills:

```mlld
import { @claude } from @mlld/claude

>> Create a custom model executor
exe @myModel(prompt) = @claude(@prompt, "opus", @base)

>> Configure with custom skills
var @myDSL = {
  model: @myModel,
  skills: ["my-custom:boot", "my-custom:run"]
}

exe @process(data) = prose:@myDSL {
  >> Your custom DSL syntax here
  analyze @data
  output result
}
```

The skill determines how the LLM interprets the prose content. OpenProse is one implementation - you can create your own DSL skills or use other prose interpreters.

## OpenProse Requirements

For OpenProse specifically:
- **Claude Code** with Opus (only model that reliably interprets OpenProse syntax)
- **OpenProse skills** approved: `open-prose:prose-boot`, `open-prose:prose-compile`, `open-prose:prose-run`

See `mlld howto exe-prose` for syntax details. OpenProse docs: https://prose.md
</PROSE_EXECUTION>

</MLLD_PATTERNS>
